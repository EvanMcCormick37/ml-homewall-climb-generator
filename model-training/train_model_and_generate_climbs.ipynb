{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58147a07-9853-4be4-a328-294b4be4ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from climb_mlp_utils import load_and_preprocess_data, train_climb_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43414d07-30d0-4982-8059-38be163fe4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Constants ---\n",
    "HOLD_PATH = 'data/holds_final.json'\n",
    "NUM_LIMBS = 2\n",
    "FEATURE_DIM = 5\n",
    "INPUT_DIM = NUM_LIMBS * FEATURE_DIM     # 2 hands × 5 features\n",
    "OUTPUT_DIM = NUM_LIMBS * FEATURE_DIM    # Next position in Feature space\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "NULL_FEATURES = [-1.0, -1.0, 0.0, 0.0, -1.0]\n",
    "\n",
    "# --- Augmentation & Math Utilities ---\n",
    "\n",
    "def mirror_climb(sequence: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Mirror a climb left-to-right. Swaps limbs and flips x-coordinates.\n",
    "    Expects sequence shape (N, 10).\n",
    "    \"\"\"\n",
    "    mirrored = sequence.copy()\n",
    "    \n",
    "    # 1. Swap LH (cols 0-4) and RH (cols 5-9)\n",
    "    mirrored[:, [0, 1, 2, 3, 4]] = sequence[:, [5, 6, 7, 8, 9]]\n",
    "    mirrored[:, [5, 6, 7, 8, 9]] = sequence[:, [0, 1, 2, 3, 4]]\n",
    "    \n",
    "    # 2. Invert norm_x (1-x) and pull_x (-x) for valid holds\n",
    "    # norm_x is at offset 0, pull_x is at offset 2\n",
    "    for limb_start_idx in [0, 5]:\n",
    "        norm_x_idx = limb_start_idx\n",
    "        pull_x_idx = limb_start_idx + 2\n",
    "        \n",
    "        # Mask: limb is not NULL (norm_x != -1)\n",
    "        mask = mirrored[:, norm_x_idx] != -1\n",
    "        \n",
    "        mirrored[mask, norm_x_idx] = 1.0 - mirrored[mask, norm_x_idx]\n",
    "        mirrored[mask, pull_x_idx] = -mirrored[mask, pull_x_idx]\n",
    "        \n",
    "    return mirrored\n",
    "\n",
    "\n",
    "def translate_climb(sequence: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate shifted max-left and shifted max-right variants.\n",
    "    Ensures all x-coordinates stay within [0, 1].\n",
    "    \"\"\"\n",
    "    # 1. Identify all valid X coordinates across both limbs\n",
    "    lh_x = sequence[:, 0]\n",
    "    rh_x = sequence[:, 5]\n",
    "    \n",
    "    valid_x_values = np.concatenate([lh_x[lh_x != -1], rh_x[rh_x != -1]])\n",
    "    \n",
    "    if valid_x_values.size == 0:\n",
    "        return sequence.copy(), sequence.copy()\n",
    "\n",
    "    # 2. Calculate max allowable shifts\n",
    "    min_x = np.min(valid_x_values)\n",
    "    max_x = np.max(valid_x_values)\n",
    "    \n",
    "    shift_left_val = min_x          # Amount to subtract to touch left wall\n",
    "    shift_right_val = 1.0 - max_x   # Amount to add to touch right wall\n",
    "\n",
    "    # 3. Apply shifts\n",
    "    left_variant = sequence.copy()\n",
    "    right_variant = sequence.copy()\n",
    "\n",
    "    for limb_idx in [0, 5]:\n",
    "        mask = sequence[:, limb_idx] != -1\n",
    "        left_variant[mask, limb_idx] -= shift_left_val\n",
    "        right_variant[mask, limb_idx] += shift_right_val\n",
    "\n",
    "    return left_variant, right_variant\n",
    "\n",
    "\n",
    "def augment_sequence_list(sequences: List[np.ndarray]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Expands a list of sequences by 6x using mirroring and translation.\n",
    "    \"\"\"\n",
    "    augmented = []\n",
    "    for seq in sequences:\n",
    "        # Generate mirrored variation\n",
    "        mirrored = mirror_climb(seq)\n",
    "        \n",
    "        # Generate translations\n",
    "        orig_l, orig_r = translate_climb(seq)\n",
    "        mir_l, mir_r = translate_climb(mirrored)\n",
    "        \n",
    "        # Add all 6 variations\n",
    "        augmented.extend([seq, orig_l, orig_r, mirrored, mir_l, mir_r])\n",
    "        \n",
    "    return augmented\n",
    "\n",
    "\n",
    "def extract_hold_features(hold_data: dict) -> List[float]:\n",
    "    \"\"\"Extract normalized 5D feature vector from hold data dict.\"\"\"\n",
    "    if hold_data == -1:\n",
    "        return list(NULL_FEATURES)\n",
    "    \n",
    "    return [\n",
    "        float(hold_data['norm_x']),\n",
    "        float(hold_data['norm_y']),\n",
    "        float(hold_data['pull_x']),\n",
    "        float(hold_data['pull_y']),\n",
    "        float(hold_data['useability']) / 10.0\n",
    "    ]\n",
    "\n",
    "\n",
    "def parse_climb_to_numpy(climb_data: dict, hold_map: dict[int, List[float]]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a raw climb dict into a (T, 10) numpy array of features.\n",
    "    \"\"\"\n",
    "    sequence_features = []\n",
    "    \n",
    "    for position in climb_data['sequence']:\n",
    "        if isinstance(position, dict) and 'holdsByLimb' in position:\n",
    "            holds = position['holdsByLimb']\n",
    "        elif isinstance(position, list):\n",
    "            holds = position\n",
    "        else:\n",
    "            print(\"Error processing position, invalid position type: \")\n",
    "            print(position, position.__class__)\n",
    "            continue\n",
    "\n",
    "        feature_list = []\n",
    "        for hold_idx in holds:\n",
    "            if isinstance(hold_idx, dict) and 'hold_id' in hold_idx:\n",
    "                hold_idx = hold_idx['hold_id']\n",
    "            if hold_idx == -1:\n",
    "                feature_list.append(NULL_FEATURES)\n",
    "            else:\n",
    "                feature_list.append(hold_map[hold_idx])\n",
    "        \n",
    "        # Combine features (Left + Right)\n",
    "        sequence_features.append(feature_list[0] + feature_list[1])\n",
    "        \n",
    "    return np.array(sequence_features, dtype=np.float32)\n",
    "\n",
    "\n",
    "# --- Dataset ---\n",
    "class ClimbDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset of (current_hands, next_hold) pairs.\n",
    "    Accepts a list of pre-processed (potentially augmented) numpy sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences: List[np.ndarray]):\n",
    "        self.examples = []\n",
    "        \n",
    "        for seq in sequences:\n",
    "            # seq shape is (T, 10)\n",
    "            # Create pairs: Input(t) -> Target(t+1)\n",
    "            for t in range(len(seq) - 1):\n",
    "                input_feat = seq[t]\n",
    "                target_feat = seq[t + 1]\n",
    "                \n",
    "                self.examples.append((\n",
    "                    torch.tensor(input_feat, dtype=torch.float32),\n",
    "                    torch.tensor(target_feat, dtype=torch.float32)\n",
    "                ))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.examples[idx]\n",
    "\n",
    "\n",
    "# --- Data Pipeline ---\n",
    "def load_and_preprocess_data(climb_paths: List[str], hold_path: str = HOLD_PATH, val_split: float = 0.2) -> Tuple[ClimbDataset, ClimbDataset, dict[int, List[float]]]:\n",
    "    \"\"\"\n",
    "    Loads JSON, converts to numpy, splits data, augments TRAINING set only,\n",
    "    and returns ClimbDatasets.\n",
    "    \"\"\"\n",
    "    print(f\"Loading hold data from {hold_path}...\")\n",
    "    with open(hold_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    hold_map = {h['hold_id']: extract_hold_features(h) for h in data['holds']}\n",
    "    all_sequences = []\n",
    "\n",
    "    for p in climb_paths:\n",
    "        print(f\"Loading climb data from {p}...\")\n",
    "        with open(p, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        all_climbs = data['climbs']\n",
    "        \n",
    "        # 1. Convert all raw JSON climbs to Numpy arrays\n",
    "        print(f\"Parsing {len(all_climbs)}sequences...\")\n",
    "        all_sequences.extend(augment_sequence_list([parse_climb_to_numpy(c,hold_map) for c in all_climbs]))\n",
    "\n",
    "    num_sequences = len(all_sequences)\n",
    "    print(num_sequences)\n",
    "\n",
    "    # 2. Split indices\n",
    "    indices = np.arange(num_sequences)\n",
    "    np.random.shuffle(indices)\n",
    "    split_idx = int(num_sequences * (1 - val_split))\n",
    "    \n",
    "    train_indices = indices[:split_idx]\n",
    "    val_indices = indices[split_idx:]\n",
    "    \n",
    "    train_seqs = [all_sequences[i] for i in train_indices]\n",
    "    val_seqs = [all_sequences[i] for i in val_indices]\n",
    "    \n",
    "    print(f\"Split: {len(train_seqs)} Train / {len(val_seqs)} Val\")\n",
    "    \n",
    "    # 4. Create Datasets\n",
    "    train_dataset = ClimbDataset(train_seqs)\n",
    "    val_dataset = ClimbDataset(val_seqs)\n",
    "    \n",
    "    return train_dataset, val_dataset, hold_map\n",
    "\n",
    "\n",
    "# --- Model ---\n",
    "class ClimbMLP(nn.Module):\n",
    "    def __init__(self, input_dim: int = INPUT_DIM,\n",
    "                 hidden_dim: int = HIDDEN_DIM,\n",
    "                 output_dim: int = OUTPUT_DIM):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# --- Training ---\n",
    "def run_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader, criterion: nn.Module, \n",
    "    optimizer: optim.Optimizer | None,\n",
    "    device: str\n",
    ") -> Tuple[float, float]:\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    \n",
    "    total_loss, total_dist, n_samples = 0.0, 0.0, 0\n",
    "    \n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            if is_train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * len(inputs)\n",
    "            # Euclidean distance for monitoring\n",
    "            total_dist += torch.norm(outputs - targets, dim=1).sum().item()\n",
    "            n_samples += len(inputs)\n",
    "\n",
    "    return total_loss / n_samples, total_dist / n_samples\n",
    "\n",
    "\n",
    "# --- Inference ---\n",
    "class ClimbGenerator:\n",
    "    \"\"\"Generate climb sequences by predicting holds in feature space.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: ClimbMLP, hold_map: dict[int, List[float]], device: str):\n",
    "        self.model = model.to(device).eval()\n",
    "        self.hold_map = hold_map\n",
    "        self.device = device\n",
    "\n",
    "    def _to_input(self, lh: List[float], rh: List[float]) -> torch.Tensor:\n",
    "        \"\"\"Convert hand features to model input tensor.\"\"\"\n",
    "        return torch.tensor(lh + rh, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def _nearest_hold(self, features: np.ndarray) -> Tuple[int, List[float]]:\n",
    "        \"\"\"Find hold with minimum Euclidean distance to predicted features.\"\"\"\n",
    "        best_id, best_dist = -1, float('inf')\n",
    "        \n",
    "        for hold_id, hold_features in self.hold_map.items():\n",
    "            dist = np.linalg.norm(features - np.array(hold_features))\n",
    "            if dist < best_dist:\n",
    "                best_id, best_dist = hold_id, dist\n",
    "                \n",
    "        return best_id, list(self.hold_map.get(best_id, NULL_FEATURES))\n",
    "\n",
    "    def generate(self, \n",
    "                 start_lh: int, \n",
    "                 start_rh: int, \n",
    "                 max_moves: int = 10) -> List[Tuple[int, int, List[float], List[float]]]:\n",
    "        \"\"\"\n",
    "        Generate a climb sequence from starting hold indices.\n",
    "        \n",
    "        Returns list of (lh_id, rh_id, lh_features, rh_features) tuples.\n",
    "        \"\"\"\n",
    "        lh = self.hold_map[start_lh]\n",
    "        rh = self.hold_map[start_rh]\n",
    "        sequence = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for move in range(max_moves):\n",
    "                inputs = self._to_input(lh, rh)\n",
    "                predicted = self.model(inputs).cpu().numpy().flatten()\n",
    "                lh_id, lh = self._nearest_hold(predicted[:5])\n",
    "                rh_id, rh = self._nearest_hold(predicted[5:])\n",
    "                \n",
    "                if (len(sequence) > 0 and (lh_id, rh_id) == sequence[-1]) or (lh == NULL_FEATURES and rh == NULL_FEATURES):\n",
    "                    break\n",
    "\n",
    "                sequence.append((lh_id, rh_id))\n",
    "                    \n",
    "        return sequence\n",
    "\n",
    "\n",
    "def train_climb_generator(\n",
    "    train_ds: Dataset,\n",
    "    val_ds: Dataset,\n",
    "    hold_map: dict[int,List[float]],\n",
    "    num_epochs: int = 100,\n",
    "    lr: float = 0.001, \n",
    "    batch_size: int = 32,\n",
    "    device: str = \"cpu\"\n",
    "    ) -> ClimbGenerator:\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = ClimbMLP().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    pbar = tqdm(range(num_epochs), desc=\"Training\")\n",
    "    for _ in pbar:\n",
    "        train_loss, train_dist = run_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_dist = run_epoch(model, val_loader, criterion, None, device)\n",
    "        \n",
    "        pbar.set_postfix({\"T_MSE\": f\"{train_loss:.4f}\", \"V_MSE\": f\"{val_loss:.4f}\"})\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_climb_mlp.pth')\n",
    "            \n",
    "    return ClimbGenerator(model, hold_map, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "215fcb01-6b83-4cd6-a1b6-e8fa17901113",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    \"holds\": \"data/holds_final.json\",\n",
    "    \"climbs\": [\"data/spraywall-climbs.json\",\"data/more-climbs.json\"]\n",
    "}\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bafac360-2e05-4b2b-bce1-ee4e8a2d165d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hold data from data/holds_final.json...\n",
      "Loading climb data from data/spraywall-climbs.json...\n",
      "Parsing sequences...\n",
      "Loading climb data from data/more-climbs.json...\n",
      "Parsing sequences...\n",
      "330\n",
      "Split: 264 Train / 66 Val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██| 150/150 [00:13<00:00, 10.74it/s, T_MSE=0.0416, V_MSE=0.0509]\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data with Augmentation\n",
    "train_ds, val_ds, hold_map = load_and_preprocess_data(PATHS[\"climbs\"], val_split=0.2)\n",
    "# 2. Train Model\n",
    "generator = train_climb_generator(train_ds, val_ds, hold_map, num_epochs=150, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7f6b47e-12df-4db6-bcf3-027185ceba76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(177, 117),\n",
       " (53, 99),\n",
       " (53, 54),\n",
       " (29, 54),\n",
       " (29, 31),\n",
       " (29, 43),\n",
       " (29, 19),\n",
       " (16, 19),\n",
       " (16, 6)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate(177,173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4d0b68d-74c8-41fe-b75e-6edc3500a471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.examples[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe279b-20ab-4980-9d94-9a276a4737c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
